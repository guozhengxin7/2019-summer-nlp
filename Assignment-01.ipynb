{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`å„ä½åŒå­¦å¤§å®¶å¥½ï¼Œæ¬¢è¿å„ä½å¼€å§‹å­¦ä¹ æˆ‘ä»¬çš„äººå·¥æ™ºèƒ½è¯¾ç¨‹ã€‚è¿™é—¨è¯¾ç¨‹å‡è®¾å¤§å®¶ä¸å…·å¤‡æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„çŸ¥è¯†ï¼Œä½†æ˜¯å¸Œæœ›å¤§å®¶å…·å¤‡åˆçº§çš„Pythonç¼–ç¨‹èƒ½åŠ›ã€‚æ ¹æ®å¾€æœŸåŒå­¦çš„å®é™…åé¦ˆï¼Œæˆ‘ä»¬è¯¾ç¨‹çš„å®Œç»“ä¹‹å èƒ½åŠ›èƒ½å¤Ÿè¶…è¿‡80%çš„è®¡ç®—æœºäººå·¥æ™ºèƒ½/æ·±åº¦å­¦ä¹ æ–¹å‘çš„ç¡•å£«ç”Ÿçš„èƒ½åŠ›ã€‚`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æœ¬æ¬¡ä½œä¸šçš„å†…å®¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. å¤ç°è¯¾å ‚ä»£ç \n",
    "\n",
    "åœ¨æœ¬éƒ¨åˆ†ï¼Œä½ éœ€è¦å‚ç…§æˆ‘ä»¬ç»™å¤§å®¶çš„GitHubåœ°å€é‡Œè¾¹çš„è¯¾å ‚ä»£ç ï¼Œç»“åˆè¯¾å ‚å†…å®¹ï¼Œå¤ç°å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. è¯·å›ç­”ä»¥ä¸‹é—®é¢˜\n",
    "\n",
    "å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå¹¶å°†é—®é¢˜å‘é€è‡³ mqgao@kaikeba.comä¸­ï¼š\n",
    "```\n",
    "    2.1. what do you want to acquire in this courseï¼Ÿ\n",
    "    2.2. what problems do you want to solveï¼Ÿ\n",
    "    2.3. whatâ€™s the advantages you have to finish you goal?\n",
    "    2.4. whatâ€™s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. å¦‚ä½•æäº¤\n",
    "ä»£ç  + æ­¤ jupyter ç›¸å…³ï¼Œæäº¤è‡³è‡ªå·±çš„ github ä¸­(**æ‰€ä»¥è¯·åŠ¡å¿…æŠŠGitHubæŒ‰ç…§ç­ä¸»ä»»è¦æ±‚å½•å…¥åœ¨Trelloä¸­**)ï¼›\n",
    "ç¬¬2é—®ï¼Œè¯·æäº¤è‡³mqgao@kaikeba.comé‚®ç®±ã€‚\n",
    "#### 4. ä½œä¸šæˆªæ­¢æ—¶é—´\n",
    "æ­¤æ¬¡ä½œä¸šæˆªæ­¢æ—¶é—´ä¸º 2019.7.6æ—¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. å®Œæˆä»¥ä¸‹é—®ç­”å’Œç¼–ç¨‹ç»ƒä¹ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŸºç¡€ç†è®ºéƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: è¯­éŸ³è¯†åˆ«ã€è‡ªåŠ¨é©¾é©¶ã€äººè„¸è¯†åˆ«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: ç”¨Githubäº¤ä½œä¸šï¼ŸğŸ˜‚ å› ä¸ºjupyteræ–¹ä¾¿æ¼”ç¤ºä»¥åŠå¯è§†åŒ–ï¼Œè€ŒPycharmä½œä¸ºIDEåœ¨å®é™…å¼€å‘ä¸­å¯ä»¥æé«˜æ•ˆç‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:ä»å·²æœ‰çš„è¯­æ–™ä¸­ï¼Œå¯ä»¥ç»Ÿè®¡å¾—åˆ°ç›¸é‚»è¯ä¹‹é—´å‡ºç°çš„æ¦‚ç‡ï¼Œä»è€Œå¯ä»¥åˆ¤æ–­ç»™å®šçš„ä¸¤ä¸ªè¯å‡ºç°çš„æ¦‚ç‡ä»¥åŠå¤šä¸ªè¯ç»„æˆçš„è¯­å¥çš„æ¦‚ç‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:æ ¹æ®è¯­æ³•è§„åˆ™ç”Ÿæˆçš„è¯­æ–™çš„åˆç†æ€§/è¾“å…¥è¿‡ç¨‹ä¸­è‡ªåŠ¨çº é”™æˆ–æ™ºèƒ½æç¤º?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:å› ä¸ºè¦åšè¯­ä¹‰ç†è§£çš„è¯ï¼Œå¾ˆéš¾åšåˆ°å®Œå…¨æ ¹æ®è¯­æ³•è§„åˆ™æŠŠä¸€å¥è¯è§„èŒƒçš„åˆ†è§£æˆè¯­æ³•è§„åˆ™çš„å„ä¸ªéƒ¨åˆ†ï¼Œå¯èƒ½è¿™å¥è¯æœ¬èº«å°±æ˜¯æœ‰è¯­æ³•é”™è¯¯çš„ã€‚ä½¿ç”¨æ¦‚ç‡æ¨¡å‹å¯ä»¥æœ‰æ›´å¥½çš„å®¹é”™æ€§ã€‚éš¾ç‚¹åœ¨äºå‰æœŸéœ€è¦å¤„ç†å¤§é‡çš„è¯­æ–™ï¼ŒåŒ…æ‹¬æ¸…æ´—ã€åˆ†è¯ã€ç»Ÿè®¡è¯ä¹‹é—´çš„æ¦‚ç‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:è¯­è¨€æ¨¡å‹æ˜¯ä¸€ä¸ªå…³äºå¤šä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:è¿™ä¸ªé—®é¢˜æ˜¯åŒ3å—ï¼Ÿæ ¹æ®è¯­æ³•è§„åˆ™ç”Ÿæˆçš„è¯­æ–™çš„åˆç†æ€§/è¾“å…¥è¿‡ç¨‹ä¸­è‡ªåŠ¨çº é”™æˆ–æ™ºèƒ½æç¤º?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:ä¸€å…ƒæ–‡æ³•æŒ‡è€ƒè™‘å•ä¸ªè¯çš„å‡ºç°æ¦‚ç‡ï¼Œç„¶åä»¥æ‰€æœ‰è¯åŒæ—¶å‡ºç°çš„æ¦‚ç‡ä½œä¸ºå¥å­çš„æ¦‚ç‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:ä¸€å…ƒæ–‡æ³•åªè€ƒè™‘å•ä¸ªè¯å‡ºç°çš„æ¦‚ç‡ï¼Œä¼˜ç‚¹å°±æ˜¯è®¡ç®—ç®€å•ï¼Œç¼ºç‚¹æ˜¯è¿™æ ·ç®—å‡ºæ¥æ•ˆæœå¹¶ä¸å¥½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:äºŒå…ƒæ–‡æ³•è€ƒè™‘ç›¸é‚»ä¸¤ä¸ªè¯å‡ºç°çš„æ¦‚ç‡ï¼Œè®¡ç®—æ‰€æœ‰ä¸¤ä¸¤è¯åŒæ—¶å‡ºç°çš„æ¦‚ç‡ä½œä¸ºå¥å­çš„æ¦‚ç‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¼–ç¨‹å®è·µéƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. è®¾è®¡ä½ è‡ªå·±çš„å¥å­ç”Ÿæˆå™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯·å®šä¹‰ä½ è‡ªå·±çš„è¯­æ³•: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "choice = random.choice\n",
    "\n",
    "def generate(gram, target, sep=''):\n",
    "    if target == \"space\": return \" \"\n",
    "    elif target not in gram: return target  # means target is a terminal expression\n",
    "\n",
    "    expaned = [generate(gram, t, sep) for t in choice(gram[target])]\n",
    "    return sep.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¬¬ä¸€ä¸ªè¯­æ³•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ±‡ç¼–è¯­å¥ åŒ…å« mov add sub ä¸‰æ¡æŒ‡ä»¤ï¼Œæ”¯æŒç›´æ¥å¯»å€/é—´æ¥å¯»å€/ç«‹å³æ•°\n",
    "\n",
    "asm_grammar_str = '''\n",
    "asm_stmt = move_stmt | add_stmt | sub_stmt\n",
    "move_stmt = move space addr_exp , value_exp\n",
    "add_stmt = add space addr_exp , value_exp\n",
    "sub_stmt = sub space addr_exp , value_exp\n",
    "value_exp = const | addr_exp\n",
    "const = num num*\n",
    "num* = null | num num*\n",
    "num = 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
    "addr_exp = direct_addr | indirect_addr\n",
    "direct_addr = reg\n",
    "reg = eax | ebx | ecx | edx\n",
    "indirect_addr = [ reg ]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "asm_grammar = create_grammar(asm_grammar_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add [ebx],7354'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(asm_grammar, \"asm_stmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¬¬äºŒä¸ªè¯­æ³•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰“æ‹›å‘¼ï¼Œè¯´è‡ªå·±çš„åå­—å’Œçˆ±å¥½\n",
    "hello_grammar_str = '''\n",
    "hello_stmt = æ‰“æ‹›å‘¼ , è¯´åå­— , è¯´çˆ±å¥½\n",
    "æ‰“æ‹›å‘¼ = ä½ ä»¬å¥½ | å¤§å®¶å¥½ | æ—©ä¸Šå¥½ | Hello | Hi\n",
    "è¯´åå­— = ä¸»è¯­ åå­—åŠ¨è¯ åå­—\n",
    "ä¸»è¯­ = æˆ‘ | ä¿º | æœ•  | æˆ‘ä»¬ | ä½ ä»¬ | ä»–ä»¬\n",
    "åå­—åŠ¨è¯ = æ˜¯ | å«  \n",
    "åå­— = å°æ˜ | å°çº¢ | å‘¨æ°ä¼¦ | Tony | Alice\n",
    "è¯´çˆ±å¥½ = ä¸»è¯­ çˆ±å¥½åŠ¨è¯ çˆ±å¥½\n",
    "çˆ±å¥½åŠ¨è¯ = å–œæ¬¢ | çƒ­çˆ±\n",
    "çˆ±å¥½ = åŠ¨è¯ åè¯\n",
    "åŠ¨è¯ = çœ‹ | åƒ | ç©¿ | ç© | å”± | æ‰“ | çˆ¬ | æ¸¸\n",
    "åè¯ = ç”µå½± | ç¯®çƒ | ä¹’ä¹“çƒ | æ­Œ | è¡£æœ | ç¾é£Ÿ | å±± | æ°´\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ç„¶åï¼Œä½¿ç”¨è‡ªå·±ä¹‹å‰å®šä¹‰çš„generateå‡½æ•°ï¼Œä½¿ç”¨æ­¤å‡½æ•°ç”Ÿæˆå¥å­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_grammar = create_grammar(hello_grammar_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä½ ä»¬å¥½,æˆ‘ä»¬æ˜¯Alice,ä»–ä»¬çƒ­çˆ±åƒç¯®çƒ'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=hello_grammar, target=\"hello_stmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ç„¶åï¼Œå®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œgenerate_nï¼Œå°†generateæ‰©å±•ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆnä¸ªå¥å­:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(gram_str, target, n=20):\n",
    "    gram = create_grammar(gram_str)\n",
    "    return [generate(gram, target) for i in range(0, n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi,æˆ‘ä»¬æ˜¯Tony,ä¿ºçƒ­çˆ±ç©å±±',\n",
       " 'å¤§å®¶å¥½,æœ•æ˜¯å‘¨æ°ä¼¦,æœ•çƒ­çˆ±åƒæ°´',\n",
       " 'ä½ ä»¬å¥½,ä»–ä»¬å«Tony,æœ•å–œæ¬¢ç©ç”µå½±',\n",
       " 'å¤§å®¶å¥½,ä»–ä»¬æ˜¯Alice,ä½ ä»¬å–œæ¬¢æ¸¸ç¯®çƒ',\n",
       " 'æ—©ä¸Šå¥½,ä¿ºå«Alice,æœ•çƒ­çˆ±æ‰“ä¹’ä¹“çƒ',\n",
       " 'å¤§å®¶å¥½,æˆ‘æ˜¯Alice,æˆ‘ä»¬çƒ­çˆ±ç©ç¯®çƒ',\n",
       " 'å¤§å®¶å¥½,æœ•å«å°æ˜,ä¿ºçƒ­çˆ±ç©¿ç¯®çƒ',\n",
       " 'æ—©ä¸Šå¥½,ä½ ä»¬æ˜¯å°æ˜,ä¿ºçƒ­çˆ±æ¸¸ä¹’ä¹“çƒ',\n",
       " 'Hi,ä¿ºå«Tony,æˆ‘ä»¬çƒ­çˆ±ç©¿æ°´',\n",
       " 'æ—©ä¸Šå¥½,æˆ‘å«Tony,æœ•å–œæ¬¢çˆ¬æ°´',\n",
       " 'æ—©ä¸Šå¥½,æˆ‘å«Alice,æˆ‘ä»¬å–œæ¬¢æ‰“ç”µå½±',\n",
       " 'å¤§å®¶å¥½,ä¿ºå«å°æ˜,æœ•çƒ­çˆ±æ‰“è¡£æœ',\n",
       " 'ä½ ä»¬å¥½,ä½ ä»¬æ˜¯å°çº¢,æœ•å–œæ¬¢å”±ç¾é£Ÿ',\n",
       " 'æ—©ä¸Šå¥½,ä¿ºæ˜¯Tony,æˆ‘ä»¬çƒ­çˆ±å”±æ­Œ',\n",
       " 'Hello,ä¿ºå«Alice,æˆ‘ä»¬çƒ­çˆ±æ¸¸ä¹’ä¹“çƒ',\n",
       " 'ä½ ä»¬å¥½,ä»–ä»¬æ˜¯å‘¨æ°ä¼¦,ä»–ä»¬å–œæ¬¢å”±å±±',\n",
       " 'æ—©ä¸Šå¥½,ä¿ºå«Alice,æˆ‘çƒ­çˆ±æ‰“ä¹’ä¹“çƒ',\n",
       " 'æ—©ä¸Šå¥½,ä¿ºå«å°çº¢,ä¿ºå–œæ¬¢ç©æ­Œ',\n",
       " 'Hi,æˆ‘æ˜¯Alice,æˆ‘çƒ­çˆ±åƒå±±',\n",
       " 'æ—©ä¸Šå¥½,ä»–ä»¬æ˜¯å‘¨æ°ä¼¦,æœ•å–œæ¬¢ç©ä¹’ä¹“çƒ']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(hello_grammar_str, target=\"hello_stmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ä½¿ç”¨æ–°æ•°æ®æºå®Œæˆè¯­è¨€æ¨¡å‹çš„è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŒ‰ç…§æˆ‘ä»¬ä¸Šæ–‡ä¸­å®šä¹‰çš„`prob_2`å‡½æ•°ï¼Œæˆ‘ä»¬æ›´æ¢ä¸€ä¸ªæ–‡æœ¬æ•°æ®æºï¼Œè·å¾—æ–°çš„Language Model:\n",
    "\n",
    "1. ä¸‹è½½æ–‡æœ¬æ•°æ®é›†ï¼ˆä½ å¯ä»¥åœ¨ä»¥ä¸‹æ•°æ®é›†ä¸­ä»»é€‰ä¸€ä¸ªï¼Œä¹Ÿå¯ä»¥ä¸¤ä¸ªéƒ½ä½¿ç”¨ï¼‰\n",
    "    + å¯é€‰æ•°æ®é›†1ï¼Œä¿é™©è¡Œä¸šé—®è¯¢å¯¹è¯é›†ï¼š https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + å¯é€‰æ•°æ®é›†2ï¼šè±†ç“£è¯„è®ºæ•°æ®é›†ï¼šhttps://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. ä¿®æ”¹ä»£ç ï¼Œè·å¾—æ–°çš„**2-gram**è¯­è¨€æ¨¡å‹\n",
    "    + è¿›è¡Œæ–‡æœ¬æ¸…æ´—ï¼Œè·å¾—æ‰€æœ‰çš„çº¯æ–‡æœ¬\n",
    "    + å°†è¿™äº›æ–‡æœ¬è¿›è¡Œåˆ‡è¯\n",
    "    + é€å…¥ä¹‹å‰å®šä¹‰çš„è¯­è¨€æ¨¡å‹ä¸­ï¼Œåˆ¤æ–­æ–‡æœ¬çš„åˆç†ç¨‹åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import fileinput\n",
    "from collections import Counter\n",
    "# jieba.enable_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_frequency(stator, sentence):\n",
    "    \"\"\"è®¡ç®—è¯é¢‘\"\"\"\n",
    "    # ç®€å•çš„åªä¿ç•™ w\n",
    "    ss = re.findall('\\w+', sentence)\n",
    "    for s in ss:\n",
    "        # ä¸€å…ƒæ–‡æ³•\n",
    "        tokens = jieba.lcut(s)\n",
    "        stator['uni_gram_token_cnt'] += len(tokens)\n",
    "        stator['uni_gram_token_countor'].update(tokens)\n",
    "        \n",
    "        # äºŒå…ƒæ–‡æ³•\n",
    "        g2_tokens = [''.join(tokens[i:i + 2]) for i in range(len(tokens[:-1]))]\n",
    "        stator['bi_gram_token_cnt'] += len(g2_tokens)\n",
    "        stator['bi_gram_token_countor'].update(g2_tokens)\n",
    "    return stator\n",
    "\n",
    "\n",
    "def stat_file(filename, stator, custom_reader=None, func_extract_sentence=lambda x: x, skip_lines=0, ignore_exp=False):\n",
    "    \"\"\"è¯»å–æ–‡ä»¶ç»Ÿè®¡è¯é¢‘\"\"\"\n",
    "    with fileinput.input(filename, openhook=fileinput.hook_encoded(\"utf-8\")) as f:\n",
    "        reader = custom_reader(f) if custom_reader else f\n",
    "        for id,line in enumerate(reader):\n",
    "            if id % 5000 == 0:\n",
    "                print(str(id) + \" ...\")\n",
    "            if id < skip_lines:\n",
    "                continue\n",
    "            try:\n",
    "                stator = calc_frequency(stator, func_extract_sentence(line))\n",
    "            except Exception as e:\n",
    "                if not ignore_exp:\n",
    "                    raise e\n",
    "    return stator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»Ÿè®¡ç»“æœ\n",
    "stator = {\n",
    "    # ä¸€å…ƒæ–‡æ³•æ€»è¯æ•°\n",
    "    \"uni_gram_token_cnt\": 0,\n",
    "    # ä¸€å…ƒæ–‡æ³•è¯é¢‘\n",
    "    \"uni_gram_token_countor\": Counter(),\n",
    "    # äºŒå…ƒæ–‡æ³•æ€»è¯æ•°\n",
    "    \"bi_gram_token_cnt\": 0,\n",
    "    # äºŒå…ƒæ–‡æ³•è¯é¢‘\n",
    "    \"bi_gram_token_countor\": Counter()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ...\n",
      "5000 ...\n",
      "10000 ...\n"
     ]
    }
   ],
   "source": [
    "# è¯»å– train æ–‡ä»¶\n",
    "stator = stat_file(\"./res/train.txt\", stator, func_extract_sentence=lambda x: x.split(\"++$++\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76593, 62960)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stator['uni_gram_token_cnt'], stator['bi_gram_token_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ...\n",
      "5000 ...\n",
      "10000 ...\n",
      "15000 ...\n",
      "20000 ...\n",
      "25000 ...\n",
      "30000 ...\n",
      "35000 ...\n",
      "40000 ...\n",
      "45000 ...\n",
      "50000 ...\n",
      "55000 ...\n",
      "60000 ...\n",
      "65000 ...\n",
      "70000 ...\n",
      "75000 ...\n",
      "80000 ...\n",
      "85000 ...\n",
      "90000 ...\n",
      "95000 ...\n",
      "100000 ...\n",
      "105000 ...\n",
      "110000 ...\n",
      "115000 ...\n",
      "120000 ...\n",
      "125000 ...\n",
      "130000 ...\n",
      "135000 ...\n",
      "140000 ...\n",
      "145000 ...\n",
      "150000 ...\n",
      "155000 ...\n",
      "160000 ...\n",
      "165000 ...\n",
      "170000 ...\n",
      "175000 ...\n",
      "180000 ...\n",
      "185000 ...\n",
      "190000 ...\n",
      "195000 ...\n",
      "200000 ...\n",
      "205000 ...\n",
      "210000 ...\n",
      "215000 ...\n",
      "220000 ...\n",
      "225000 ...\n",
      "230000 ...\n",
      "235000 ...\n",
      "240000 ...\n",
      "245000 ...\n",
      "250000 ...\n",
      "255000 ...\n",
      "260000 ...\n"
     ]
    }
   ],
   "source": [
    "# è¯»å– movie_comments.csv\n",
    "import csv\n",
    "stator = stat_file(\"./res/movie_comments.csv\", stator, custom_reader=csv.reader, func_extract_sentence=lambda x: x[3], skip_lines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4643686, 3646353)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stator['uni_gram_token_cnt'], stator['bi_gram_token_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def prob_uni_gram(word, stator): \n",
    "    \"\"\"è®¡ç®—ä¸€ä¸ªè¯çš„æ¦‚ç‡\"\"\"\n",
    "    if word in stator['uni_gram_token_countor']:\n",
    "        return stator['uni_gram_token_countor'][word] / stator['uni_gram_token_cnt']\n",
    "    else:\n",
    "        return 1 / stator['uni_gram_token_cnt']\n",
    "\n",
    "prob_1 = partial(prob_uni_gram, stator=stator)\n",
    "\n",
    "\n",
    "def prob_bi_gram(word1, word2, stator):\n",
    "    \"\"\"è®¡ç®—ä¸¤ä¸ªè¯çš„æ¦‚ç‡\"\"\"\n",
    "    if word1 + word2 in stator['bi_gram_token_countor']:\n",
    "        return stator['bi_gram_token_countor'][word1+word2] / stator['uni_gram_token_countor'][word2]\n",
    "    else:\n",
    "        return 1 / stator['bi_gram_token_cnt']\n",
    "\n",
    "prob_2 = partial(prob_bi_gram, stator=stator)\n",
    "\n",
    "\n",
    "def get_probablity(sentence):\n",
    "    \"\"\"è®¡ç®—å¥å­çš„æ¦‚ç‡\"\"\"\n",
    "    words = jieba.lcut(sentence)\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.011205107322071303, 2.153461711235428e-07)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_1(\"æˆ‘\"), prob_1(\"æˆ‘å•Šå•Š\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015494918970165614, 2.962699611886351e-05, 2.7424662395549746e-07)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2(\"çœ‹\",\"ç”µå½±\"), prob_2(\"æ‰“\",\"ç”µå½±\"), prob_2(\"æ‰“\",\"çƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7468720703359976e-06"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probablity(\"æˆ‘ä»¬å»çœ‹ç”µå½±å§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. è·å¾—æœ€ä¼˜è´¨çš„çš„è¯­è¨€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“æˆ‘ä»¬èƒ½å¤Ÿç”Ÿæˆéšæœºçš„è¯­è¨€å¹¶ä¸”èƒ½åˆ¤æ–­ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”Ÿæˆæ›´åŠ åˆç†çš„è¯­è¨€äº†ã€‚è¯·å®šä¹‰ generate_best å‡½æ•°ï¼Œè¯¥å‡½æ•°è¾“å…¥ä¸€ä¸ªè¯­æ³• + è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆ**n**ä¸ªå¥å­ï¼Œå¹¶èƒ½é€‰æ‹©ä¸€ä¸ªæœ€åˆç†çš„å¥å­: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æç¤ºï¼Œè¦å®ç°è¿™ä¸ªå‡½æ•°ï¼Œä½ éœ€è¦Pythonçš„sortedå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(): # you code here\n",
    "    return sorted([(i, get_probablity(i)) for i in generate_n(hello_grammar_str, target=\"hello_stmt\", n=200)], key=lambda x: x[1], reverse=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ä½ ä»¬å¥½,æˆ‘ä»¬æ˜¯å‘¨æ°ä¼¦,æˆ‘å–œæ¬¢æ‰“æ°´', 6.929720381496959e-38)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬å®ç°äº†è‡ªå·±çš„ç¬¬ä¸€ä¸ªAIæ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ¯”è¾ƒæ¥è¿‘äºäººç±»çš„è¯­è¨€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: è¿™ä¸ªæ¨¡å‹æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ ä½ å‡†å¤‡å¦‚ä½•æå‡ï¼Ÿ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "1. è¯åº“åå°ï¼Œå¾ˆå¤šè¯æ²¡æœ‰åœ¨è¯åº“ä¸­å‡ºç°è¿‡ã€‚\n",
    "2. å¦å¤–æ„Ÿè§‰è§„åˆ™ä¸èƒ½è‡ªç”±åº¦å¤ªå¤§ï¼Œæ¯”å¦‚çˆ±å¥½å°±å¯ä»¥ç›´æ¥æ˜¯ æ‰“ç¯®çƒ/çœ‹ç”µå½±ï¼Œè€Œä¸åº”è¯¥ä¿ç•™å¤ªå¤§çš„è‡ªç”±åº¦ã€‚\n",
    "3. è€Œä¸”æ„Ÿè§‰äºŒå…ƒæ–‡æ³•åªå¯¹ä¸€å¥è¯åˆ¤æ–­çš„æ¦‚ç‡æ¯”è¾ƒå¥½ï¼Œå¦‚æœæ˜¯å¤šå¥è¯ï¼Œé‚£ä¹ˆå‰åå¯èƒ½æ¯«æ— å…³è”ï¼Œå‡ºç°æ²¡æœ‰æ„ä¹‰çš„å¥å­ã€‚\n",
    "\n",
    "è§£å†³çš„è¯æ¯”è¾ƒèƒ½å¿«é€Ÿæå‡æ•ˆæœå°±æ˜¯æ”¹è¿›è§„åˆ™ï¼Œä½†æ˜¯è¿™å°±æ„Ÿè§‰æ›´â€œæœ‰å¤šå°‘äººå·¥å°±æœ‰å¤šå°‘æ™ºèƒ½â€äº†ğŸ˜‚ã€‚ \n",
    "\n",
    "å…¶ä»–çš„æš‚æ—¶ä¸çŸ¥é“æ€ä¹ˆè§£å†³ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ä»¥ä¸‹å†…å®¹ä¸ºå¯é€‰éƒ¨åˆ†ï¼Œå¯¹äºç»å¤§å¤šæ•°åŒå­¦ï¼Œèƒ½å®Œæˆä»¥ä¸Šçš„é¡¹ç›®å·²ç»å¾ˆä¼˜ç§€äº†ï¼Œä¸‹è¾¹çš„å†…å®¹å¦‚æœä½ è¿˜æœ‰ç²¾åŠ›å¯ä»¥è¯•è¯•ï¼Œä½†ä¸æ˜¯å¿…é¡»çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) å®ŒæˆåŸºäºPattern Matchçš„è¯­å¥é—®ç­”\n",
    "> æˆ‘ä»¬çš„GitHubä»“åº“ä¸­ï¼Œæœ‰ä¸€ä¸ªassignment-01-optional-pattern-matchï¼Œè¿™ä¸ªéš¾åº¦è¾ƒå¤§ï¼Œæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥æŒ‘æˆ˜ä¸€ä¸‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) å®Œæˆé˜¿å…°å›¾çµæœºå™¨æ™ºèƒ½åŸå§‹è®ºæ–‡çš„é˜…è¯»\n",
    "1. è¯·é˜…è¯»é˜¿å…°å›¾çµå…³äºæœºå™¨æ™ºèƒ½çš„åŸå§‹è®ºæ–‡ï¼šhttps://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. å¹¶æŒ‰ç…§GitHubä»“åº“ä¸­çš„è®ºæ–‡é˜…è¯»æ¨¡æ¿ï¼Œå¡«å†™å®Œæ¯•åå‘é€ç»™æˆ‘: mqgao@kaikeba.com è°¢è°¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å„ä½åŒå­¦ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†è‡ªå·±çš„ç¬¬ä¸€ä¸ªAIæ¨¡å‹ï¼Œå¤§å®¶å¯¹äººå·¥æ™ºèƒ½å¯èƒ½å·²ç»æœ‰äº†ä¸€äº›æ„Ÿè§‰ï¼Œäººå·¥æ™ºèƒ½çš„æ ¸å¿ƒå°±æ˜¯ï¼Œæˆ‘ä»¬å¦‚ä½•è®¾è®¡ä¸€ä¸ªæ¨¡å‹ã€ç¨‹åºï¼Œåœ¨å¤–éƒ¨çš„è¾“å…¥å˜åŒ–çš„æ—¶å€™ï¼Œæˆ‘ä»¬çš„ç¨‹åºä¸å˜ï¼Œä¾ç„¶èƒ½å¤Ÿè§£å†³é—®é¢˜ã€‚äººå·¥æ™ºèƒ½æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„é¢†åŸŸï¼Œç›®å‰å¤§å®¶æ‰€ç†ŸçŸ¥çš„æ·±åº¦å­¦ä¹ åªæ˜¯å…¶ä¸­ä¸€å°éƒ¨åˆ†ï¼Œä¹‹åä¹Ÿè‚¯å®šä¼šæœ‰æ›´å¤šçš„æ–¹æ³•æå‡ºæ¥ï¼Œä½†æ˜¯å¤§å®¶çŸ¥é“äººå·¥æ™ºèƒ½çš„ç›®æ ‡ï¼Œå°±çŸ¥é“äº†ä¹‹åè¿›æ­¥çš„æ–¹å‘ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åï¼Œå¸Œæœ›å¤§å®¶å¯¹AIä¸è¦æœ‰ææƒ§æ„Ÿï¼Œè¿™ä¸ªå¹¶ä¸éš¾ï¼Œå¤§å®¶åŠ æ²¹ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
